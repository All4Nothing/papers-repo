# **End-to-End Object Detection with Transformers**

- ***Link :*** https://arxiv.org/abs/2005.12872

![1](https://github.com/user-attachments/assets/66d45eeb-4b7f-4de6-8fb7-a396262559c3)

### ğŸ’¡ ì´ ë…¼ë¬¸ì˜ ì¥ì ì€?

- ê¸°ì¡´ì˜ ê°ì²´ íƒì§€(Object detection) ê¸°ìˆ ê³¼ ë¹„êµí–ˆì„ ë•Œ ë§¤ìš° ê°„ë‹¨í•˜ë©° ë˜í•œ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.

### ğŸ’¡ ì´ ë…¼ë¬¸ì´ ì œì•ˆí•œ ê²ƒì€?

- DEtection TRansformer, DETRì€ Bipartite matching loss function(ì´ë¶„ ë§¤ì¹­ ì†ì‹¤ í•¨ìˆ˜)ë¥¼ ì œì‹œí–ˆê³ , Transformerë¥¼ ì´ìš©í•œ object detection taskë¥¼ ìˆ˜í–‰í•œë‹¤.

## Overall training procedure

1. Extract feature map by CNN backbone
    - CNNì„ backbone networkë¡œ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ featuresë¥¼ ì¶”ì¶œí•œë‹¤.
2. Add Positional Encoding
    - ì´ë¯¸ì§€ì—ì„œ ìƒëŒ€ì ì¸ ìœ„ì¹˜ ì •ë³´ë¥¼ ë‹´ê¸° ìœ„í•´ positional encodingì„ ì¶”ê°€í•˜ì—¬ encoderë¡œ ë“¤ì–´ê°„ë‹¤.
3. Generate Object queires
4. Output encoder memory by Transformer encoder
5. Output embedding by Transformer decoder
6. Class prediction by Class head
7. Bounding box prediction by Bounding box head
8. Match prediction with ground truth by Hungarian Matcher
9. Compute losses

## Background

- ê¸°ì¡´ object detectionì€ ì£¼ë¡œ pre-defined anchorì„ ì‚¬ìš©í•œë‹¤. ì´ëŠ” ì´ë¯¸ì§€ ë‚´ ê³ ì •ëœ ì§€ì ë§ˆë‹¤ ë‹¤ì–‘í•œ scale, aspect ratioë¥¼ ê°€ì§„ anchorë¥¼ ìƒì„±í•˜ê³ , anchor ê¸°ë°˜ìœ¼ë¡œ ìƒì„±í•œ ì˜ˆì¸¡ bounding boxì™€ ground truthë¥¼ ë§¤ì¹­í•œë‹¤. ì´ë•Œ ground truthì™€ì˜ IoUê°’ì´ íŠ¹ì • threshold ì´ìƒì¼ ê²½ìš° positive sampleë¡œ ê°„ì£¼í•˜ë©°, positive sampleì— ëŒ€í•´ì„œë§Œ bounding box regressionì„ ìˆ˜í–‰í•œë‹¤. ì´ì²˜ëŸ¼ í•˜ë‚˜ì˜ ground truthì— ëŒ€í•´ ë‹¤ìˆ˜ì˜ bounding boxê°€ ë§¤ì¹­ë˜ëŠ”, ì˜ˆì¸¡ bounding boxì™€ ground truth ê°„ì˜ many-to-one ê´€ê³„ê°€ ì„±ë¦½í•œë‹¤.

## Bipartite Matching

![2](https://github.com/user-attachments/assets/a009ae87-2bdb-4f2c-b466-808f0cea4ace)  

- ê¸°ì¡´ object detection ë°©ë²•ë“¤ì€ ë„ˆë¬´ ë³µì¡í•˜ë©° ë‹¤ì–‘í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•œë‹¤. ë˜í•œ, bounding boxì˜ í˜•íƒœ, bounding boxê°€ ê²¹ì¹  ë•Œì˜ ì²˜ë¦¬ ë°©ë²•ê³¼ ê°™ì€ prior knowledge(ì‚¬ì „ ì§€ì‹)ê°€ ìš”êµ¬ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íƒì§€í•˜ê³ ì í•˜ëŠ” objectê°€ ê¸°ì°¨ì™€ ê°™ì´ ê¸´ ë¬¼ì²´ì¼ ê²½ìš° bounding boxë¥¼ ê¸¸ê²Œ ì„¤ì •í•œë‹¤ë˜ê°€ í•˜ëŠ” ê²ƒì´ë‹¤.
- ë˜í•œ, í•˜ë‚˜ì˜ ground truthë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë‹¤ìˆ˜ì˜ bounding boxê°€ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì— ì´ëŸ¬í•œ near-duplicateí•œ ì˜ˆì¸¡, redundantí•œ ì˜ˆì¸¡ì„ ì œê±°í•˜ê¸° ìœ„í•´ NMS(Non Maximum Supppresion)ê³¼ ê°™ì€ post-processing ê³¼ì •ì´ ë°˜ë“œì‹œ í•„ìš”í•˜ë‹¤.
- ì´ ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ bipartite matching(ì´ë¶„ ë§¤ì¹­)ì„ í†µí•´ set prediction problemì„ ì§ì ‘ì ìœ¼ë¡œ í•´ê²°í•œë‹¤. ì—¬ê¸°ì„œ setì€ ìˆ˜í•™ì—ì„œ ë§í•˜ëŠ” ì§‘í•©ì´ë‹¤. ì§‘í•©ì€ ì¤‘ë³µë˜ëŠ” ì›ì†Œê°€ ì—†ê³ , ì›ì†Œì˜ ìˆœì„œ ë˜í•œ ìƒê´€ì´ ì—†ë‹¤.
- ì´ë¯¸ì§€ì—ì„œ íƒì§€í•  objectì˜ ê°œìˆ˜ë¥¼ ê³ ì •í•´ë‘ë©´, ì´ë¶„ ë§¤ì¹­ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.
![3](https://github.com/user-attachments/assets/42b3e57b-f8cf-47cb-a591-1f6932d16555)  
- ì´ë•Œ, Hungarian algorithmì„ ì‚¬ìš©í•˜ì—¬ lossê°€ ê°€ì¥ ì‘ê²Œ ë‚˜ì˜¤ë„ë¡,  ground-truthì™€ predictionì‚¬ì´ì˜ ì´ë¶„ ë§¤ì¹­í•œë‹¤.

### Generalized Intersection over Union, GIoU

- GIoU lossëŠ” ë‘ box ì‚¬ì´ì˜ IoUê°’ì„ í™œìš©í•œ lossë¡œ scale-invariant(ì²™ë„ ë¶ˆë³€)í•˜ë‹¤ëŠ” íŠ¹ì§•ì´ ìˆë‹¤.
- GIoUë¥¼ êµ¬í•˜ê¸° ìœ„í•´ì„œëŠ” predicted box $b_{\sigma(i)}$ì™€ ground truth box $\hat{b_i}$ë¥¼ ë‘˜ëŸ¬ì‹¸ëŠ” ê°€ì¥ ì‘ì€ box $B(b_{\sigma(i)},\hat{b})$ë¥¼ êµ¬í•œë‹¤. ì´ë•Œ, predicted boxì™€ ground truth boxê°€ ë§ì´ ê²¹ì¹ ìˆ˜ë¡ $B(b_{\sigma(i)},\hat{b})$ê°€ ì‘ì•„ì§€ë©°, ë‘ boxê°€ ë©€ì–´ì§ˆìˆ˜ë¡ $B(b_{\sigma(i)},\hat{b})$ê°€ ì»¤ì§„ë‹¤.
- $IoU(b_{\sigma(i)},\hat{b})$ëŠ” ë‘ box ì‚¬ì´ì˜ IoUë¥¼ ì˜ë¯¸í•˜ë©°, $\frac{|B(b_{\sigma(i)},\hat{b}| \setminus b_{\sigma(i)}\cup \hat{b_i} }{|B(b_{\sigma(i)},\hat{b}|}$ëŠ” $B(b_{\sigma(i)},\hat{b})$ì—ì„œ predicted boxì™€ ground truth boxë¥¼ í•©í•œ ì˜ì—­ì„ ëº€ ì˜ì—­ì— í•´ë‹¹í•œë‹¤. GIoUëŠ” -1ì—ì„œ 1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§€ë©°, GIoU lossë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” 1-GIoU í˜•íƒœë¡œ ì‚¬ìš©í•œë‹¤.
- $L_{box}(b_{\sigma(i)},\hat{b})=\lambda_{iou}L_{iou}(b_{\sigma(i)},\hat{b})+\lambda_{L1}||b_{\sigma(i)}-\hat{b}||_1$, $\lambda_{iou},\lambda_{L1}$ì€ ë‘ term ì‚¬ì´ë¥¼ ì¡°ì •í•˜ëŠ” scalar hyperparameter

## Transformer
![4](https://github.com/user-attachments/assets/76d6afe9-1baf-4ba5-b8b7-b371896d713c)  

DETRì—ì„œ ì‚¬ìš©í•˜ëŠ” Transformerì™€ NLP taskì—ì„œ ì‚¬ìš©í•˜ëŠ” TransformerëŠ” ì°¨ì´ì ì´ ìˆë‹¤.

1. TransformerëŠ” encoderì—ì„œ ë¬¸ì¥ì— ëŒ€í•œ embeddingì„ ì…ë ¥ë°›ëŠ” ë°˜ë©´, DETRì€ ì´ë¯¸ì§€ feature mapì„ ë°›ëŠ”ë‹¤.
2. TransformerëŠ” decoderì— target embeddingì„ ì…ë ¥í•˜ëŠ” ë°˜ë©´, DETRì€ object queriesë¥¼ ì…ë ¥í•œë‹¤.
3. TransformerëŠ” decoderì—ì„œ ì²« ë²ˆì§¸ attention ì—°ì‚° ì‹œ masked multi-head attentionì„ ìˆ˜í–‰í•˜ëŠ” ë°˜ë©´, DETRì€ multi-head self-attentionì„ ìˆ˜í–‰í•œë‹¤.
4. TransformerëŠ” decoder ì´í›„ í•˜ë‚˜ì˜ headë¥¼ ê°€ì§€ëŠ” ë°˜ë©´, DETRì€ ë‘ ê°œì˜ headë¥¼ ê°€ì§„ë‹¤.


### Encoder

![5](https://github.com/user-attachments/assets/3c9c86af-36bb-4320-8653-ab85e576b72b)  

- EncoderëŠ” $d \times HW$í¬ê¸°ì˜ ì—°ì†ì„±ì„ ë ëŠ” feature mapì„ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ”ë‹¤. ì´ë•Œ $d$ëŠ” image featurefë¥¼ ì˜ë¯¸í•˜ê³  $HW$ëŠ” ê°ê°ì˜ í”½ì…€ ìœ„ì¹˜ ì •ë³´ë¥¼ ë‹´ê³  ìˆë‹¤.
- Encoderì˜ self-attention mapì„ ì‹œê°í™”í•´ë³´ë©´ ê°œë³„ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì ì ˆíˆ ë¶„ë¦¬í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

### Decoder

![6](https://github.com/user-attachments/assets/3be1186b-11d2-47d4-b53a-e3f70031e9cb)  

- DecoderëŠ” $N$ê°œì˜ object query(í•™ìŠµëœ ìœ„ì¹˜ ì„ë² ë”©)ë¥¼ ì´ˆê¸° ì…ë ¥ìœ¼ë¡œ ì´ìš©í•œë‹¤. ì¸ì½”ë”ê°€ global attentionì„ í†µí•´ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë¶„ë¦¬í•œ ë’¤ì— ë””ì½”ë”ëŠ” ê° ì¸ìŠ¤í„´ìŠ¤ì˜ í´ë˜ìŠ¤ì™€ ê²½ê³„ì„ ì„ ì¶”ì¶œí•œë‹¤.
