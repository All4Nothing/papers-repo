# AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE

- ***Link :*** https://arxiv.org/abs/2010.11929

ì´ ë…¼ë¬¸ì—ì„œëŠ” NLPì—ì„œ ì‚¬ìš©ë˜ëŠ” Transformerë¥¼ ì´ìš©í•˜ì—¬ Image Classificationì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” Vision Transformer ëª¨ë¸ì„ ì†Œê°œí•œë‹¤.


ğŸ’¡ **Model Architecture** 
![IMG_1268](https://github.com/user-attachments/assets/286dde83-b8bd-4036-bb44-7bb3a29b5e2d)  
ëª¨ë¸ì˜ êµ¬ì¡°ëŠ” ìœ„ì™€ ê°™ë‹¤.

![IMG_1271](https://github.com/user-attachments/assets/f534e486-4c4a-4cf8-b1e6-4d23702540cb)  
ë¨¼ì € 2Dì´ë¯¸ì§€ë¥¼ 1ì°¨ì›ìœ¼ë¡œ(Flattening) Embeddingí•˜ê¸° ìœ„í•´, ì´ë¯¸ì§€ë¥¼ Patchë‹¨ìœ„ë¡œ ìª¼ê¹¨ëŠ” Patch Embeddingì„ ìˆ˜í–‰í•œë‹¤.  
Patch Embeddingì€ $x \in \mathbb{R}^{H \times W \times C}$ ì´ë¯¸ì§€ë¥¼ patch ë‹¨ìœ„ë¡œ ìª¼ê°œì–´, ê° patchê°€ $x_p \in \mathbb{R}^{N\times (P^2 \cdot C)}$ë˜ë„ë¡ ë§Œë“¤ì–´ì¤€ë‹¤.
- H: Height, W: Width, C: Channels
- $N=HW/P^2$

ì¶”ê°€ë¡œ, BERTì—ì„œ ì‚¬ìš©í•˜ëŠ” [Class] í† í°ê³¼ ë¹„ìŠ·í•˜ê²Œ Input Embeddingì˜ ë§¨ ì•ì— [Class] Patchë¥¼ ë„£ì–´ì¤€ë‹¤. [Class] íŒ¨ì¹˜ëŠ” Transformer Encoderì˜ ì¶œë ¥($z_l$
)ì˜ ë§¨ ì•($z_l^0$)ì— ëŒ€ì‘ë˜ë©° ì´í›„ MLPì˜ inputìœ¼ë¡œ ë“¤ì–´ê°€ classificationì— ì‚¬ìš©ëœë‹¤.  
ë˜í•œ ê° patchë“¤ì˜ ìˆœì„œì •ë³´ë¥¼ ë„£ì–´ì£¼ê¸° ìœ„í•´ Positional Encodingì„ ê° Patch Embeddingì— ë”í•´ì¤€ë‹¤.  
![IMG_1274](https://github.com/user-attachments/assets/f015fcac-41bb-4a9e-9640-1a2c1e6c489f)  
Positional Encodingì€ ìœ„ ì‚¬ì§„ ì¤‘ ê°€ìš´ë°ì˜ ëª¨ìŠµì²˜ëŸ¼, ìì‹ ì˜ patchê°€ ê°€ì¥ í™œì„±í™”ë˜ì–´ìˆëŠ” ëª¨ìŠµì„ ë³¼ ìˆ˜ ìˆë‹¤.( (1,1) patchëŠ” ì™¼ìª½ ë§¨ìœ„ ëª¨ì„œë¦¬ê°€ ê°€ì¥ í™œì„±í™” ë˜ì–´ìˆìŒ)  
ì´ì™€ ê°™ì€ positional encodingì„ patch embeddingì— ë”í•´ì¤˜ ìœ„ì¹˜ê°’ì„ ë³´ì¡´í•  ìˆ˜ ìˆë‹¤.  
ì´ë ‡ê²Œ êµ¬í•´ì§„ ë²¡í„°ë¥¼ Transformer Encoderì˜ inputìœ¼ë¡œ ë„£ì–´ì£¼ê³ , Transformer Encoderë¡œë¶€í„° ì¶œë ¥í•œ Outputì„ MLPì˜ inputìœ¼ë¡œ ë„£ì–´ image classificationì„ ìˆ˜í–‰í•œë‹¤.  
ì´ë•Œ, ì—¬ê¸°ì„œ ì‚¬ìš©í•œ Transformer EncoderëŠ” ê¸°ì¡´ì˜ Transformerì˜ Encoderì™€ëŠ” êµ¬ì¡°ê°€ ì¡°ê¸ˆ ë‹¤ë¥´ë‹¤.

![IMG_1273](https://github.com/user-attachments/assets/051745ca-71be-46d1-ae1d-4c6708d502e8)  
*Transforemr - Attention Is All You Need*

ì—¬ê¸°ì„œ ì‚¬ìš©í•œ Transformer EncoderëŠ” Normalizationì„ ë¨¼ì € ìˆ˜í–‰í•´ì£¼ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.  
ìœ„ ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

![IMG_1272](https://github.com/user-attachments/assets/120f5c42-db68-4fb5-9f77-d7953c618dd0)  
*ViTë¥¼ ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„*
- MSA: Multi-Head Self-Attention
- LN: Layer-Normalization
- $Z'_l, Z_l$ì—ì„œ residual connection($+z_{l-1},z'_l$) ì‚¬ìš©


ğŸ’¡ **Hybrid Architecture**  
ì´ë¯¸ì§€ë¥¼ Patchë‹¨ìœ„ë¡œ ìª¼ê°œì–´ Linear Projectionì„ í†µí•´ Embedding Vectorë¡œ ë§Œë“œëŠ” ëŒ€ì‹ ì—, CNNì„ ì´ìš©í•˜ì—¬ êµ¬í•œ Feature Mapì„ Transformerì˜ input vectorìœ¼ë¡œ ë„£ì–´ ì‚¬ìš©í•  ìˆ˜ë„ ìˆë‹¤.

ğŸ’¡ **Result**

![IMG_1270](https://github.com/user-attachments/assets/5968b0d7-149b-423a-a330-2e309548c5d0)  

ê° ì´ë¯¸ì§€ì˜ ì ì ˆí•œ ë¶€ë¶„ì´ í™œì„±í™”ëœ ëª¨ìŠµì„ ë³¼ ìˆ˜ ìˆë‹¤.

ğŸ’¡ **Self-Supervision** 

BERTì—ì„œ self-supervised pre-trainingì„ í•œ ê²ƒì²˜ëŸ¼, ViTì—ì„œë„ Patchì˜ ì¼ë¶€ë¥¼ maskingí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì„±ëŠ¥ì„ í–¥ìƒ ì‹œí‚¤ë ¤ëŠ” ì‹œë„ë¥¼ í–ˆë‹¤.
